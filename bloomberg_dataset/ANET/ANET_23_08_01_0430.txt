Q2 2023 Earnings Call
Company Participants
Anshul Sadana, Chief Operating Officer
Ita Brennan, Chief Financial Officer
Jayshree V. Ullal, President and Chief Executive Officer
Liz Stine, Director, Investor Relations
Other Participants
Aaron Rakers, Wells Fargo
Amit Daryanani, Evercore
Antoine Chkaiban, New Street Research
Ben Bollin, Cleveland Research Company
Ben Reitzes, Melius Research
David Vogt, UBS
Erik Suppiger, JMP Securities
George Notter, Jefferies
James E. Fish, Piper Sandler
Karl Ackerman, BNP Paribas
Matthew Niknam, Deutsche Bank
Meta Marshall, Morgan Stanley
Michael Ng, Goldman Sachs
Samik Chatterjee, JP Morgan
Sebastian Naji, William Blair
Simon Leopold, Raymond James
Tal Liani, Bank of America
Tim Long, Barclays
Presentation
Operator
Welcome to the Second Quarter 2023 Arista Networks' Financial Results Earnings Conference Call. During the call, all participants will be in a listen-only mode. After the presentation, we will conduct a question-and-answer session, instructions will be provided at that time. (Operator Instructions) As a reminder, this conference is being recorded and will be available for replay from the Investor Relations section at the Arista website following this call.

Ms.Liz Stine, Arista's Director of Investor Relations, you may begin.

Liz Stine{BIO 22543302 <GO>}
Thank you, operator. Good afternoon, everyone, and thank you for joining us. With me on today's call are: Jayshree Ullal, Arista Networks' President and Chief Executive Officer; and Ita Brennan, Arista's Chief Financial Officer. This afternoon, Arista Network issued a press release announcing the results for its fiscal second quarter ending June 30, 2023. If you would like a copy of the release, you can access it online at our website.

During the course of this conference call, Arista Networks' management will make forward-looking statements, including those relating to our financial outlook for the third quarter of the 2023 fiscal year, longer-term financial outlooks for 2023 and beyond, our total addressable market and strategy for addressing these market opportunities, including AI, customer demand trends, supply chain constraints, component costs, manufacturing output, inventory management, and inflationary pressures on our business, lead time, product innovation, working capital optimization, and the benefits of acquisitions, which are subject to the risks and uncertainties that we discuss in detail in our documents filed with the SEC. Specifically, in our most recent Form 10-Q and Form 10-K, and which could cause actual results to differ materially from those anticipated by these statements.

These forward-looking statements apply as of today and you should not rely on them as representing our views in the future. We undertake no obligation to update these statements after this call. Also, please note that certain financial measures we use on this call are expressed on a non-GAAP basis and have been adjusted to exclude certain charges. We have provided reconciliations of these non-GAAP financial measures to GAAP financial measures in our earnings press release.

With that, I will turn the call over to Jayshree.

Jayshree V. Ullal{BIO 1737637 <GO>}
Thank you, Liz, and happy last day in July, everyone. We delivered revenues of $1.46 billion for the quarter with a non-GAAP earnings per share of $1.58. Services and software support renewals contributed approximately 15.2% of revenue. Our non-GAAP gross margins of 61.3% was influenced by improving supply chain overheads and higher enterprise contributions. We do expect gross margins to consistently improve every quarter this year and stabilize in 2024. International contribution registered at 21%, with the Americas at 79%. As we surpass 75 million cumulative cloud networking ports, we are experiencing three refresh cycles with our customers. 100-gigabit migration in the enterprises, 200 and 400-gigabit migration in the cloud, and 400-gigabit going to 800-gigabit for AI workloads.

During the past couple of years, we have enjoyed significant increase in cloud CapEx to support our cloud titan customers for their ever-growing needs, tech refresh, and expanded offerings. Each customer brings a different business and mix of AI networking and classic cloud networking for their compute and storage clusters. One specific cloud titan customer has signaled a slowdown in CapEx from previously elevated levels. Therefore, we expect near-term cloud titan demand to moderate with spend favoring their AI investments. We do project, however, that we will grow in excess of 30% annually versus our prior Analyst Day forecast of 25% in 2023. The AI opportunity is exciting. As our largest cloud customers review their classic cloud and AI networking plans, Arista is adapting to these changes, thereby doubling down on our investments in AI. Arista is a proud founding member of the Ultra Ethernet Consortium that is on a mission to build open, multi-vendor AI networking at scale based on proven Ethernet and IP.

There are a lot of software and EOS considerations for AI. AI traffic and performance demands are different as it comprises of a small number of synchronized high-bandwidth flows, making them prone to collisions that slow down the job completion time of AI clusters. As we connect thousands of GPUs, generating billions of parameters for pedestal called clusters, Arista's EOS capabilities must also scale along with our AI spine fine and leaf platforms to achieve that consistent performance and throughput. Arista has been developing EOS features such as intelligent load balancing and advanced analyzers to report and rebalance flows that can achieve predictable performance. Customers can now pick and choose programmable packet header fields for better entropy and efficient load balancing of their AI workloads.

Network visibility is also important in the training phase for large datasets to improve the accuracy of large language models. Arista's new AI analyzer monitors and reports traffic counters at microsecond-level windows to detect and address microbursts. Our AI strategy and platforms are resonating well with our early customers. Presently, in 2023, we are in the middle of trials for back-end AI networks, leading to pilots in 2024. We expect larger clusters and production deployments in 2025 and beyond. In the decade ahead, AI networking will become an extension of cloud networking to form a cohesive and seamless front-end and back-end network.

In the non-cloud enterprise category, we continue to experience good momentum in both data center and campus. Let me illustrate with a few customer wins. The first is an international new transportation win where the customer was seeking to modernize their legacy campus. Their endpoints included large and small campus locations, internal communication devices, various IoTs, CCTV, display boards, and much more. The customer mandated a fully automated workflow. Arista presented a highly optimized, best-of-class cognitive campus. With Arista's single binary EOS image across all campus platforms, complete with a universal API and built-in automation features, the customer was set on a path to continued campus modernization. The next enterprise win involves both data center and campus with advanced EVPN, L3VPN, over VXLAN routing architectures instead of the traditional layer two extension.

Distributed AVA sensors were strategically positioned within the network to capture and analyze traffic at critical points. This zero trust approach emphasizes threat mitigation throughout the network as opposed to relying solely on silo security. The integration of real-time streaming telemetry and visibility capabilities proved to be paramount in obtaining this operational acceptance. The final win was in a large public sector connecting redundant data centers to hundreds of campus locations with a large routing environment. They were challenged with complex MPLS routing that was hard to operate across the WAN and campus network. An upgrade of any magnitude implied several million dollars impacting change controls to touch on all their sites. Arista demonstrated that the customer could use a single sign for both LAN and WAN to dramatically simplify and automate the whole environment within 30 days. This 80% reduction in total cost of ownership was made possible with Arista's modern cloud operating model. You can see a recurring theme here across all these customer wins, which is the power of our platform innovation, quality, and support with a low TCO and a single cloud vision and EOS software stack. Arista is diversifying its business to transform the enterprise to a modern network operating model.

Before I hand to Ita, I would like to share with you that Ita is planning to retire sometime next year in 2024. She has had a stellar career at Arista as our Chief Financial Officer. Ita has been our business partner and friend for the past eight years. She has displayed the Arista way, always prioritizing our customers, employees, and shareholders. Ita has demonstrated and delivered both growth and profitability with a very, very small G&A investment, often only 1.5% of revenue. These types of pristine financials are so rare in a fast-growing tech company and only possible with a shared vision between the CFO and CEO.

Ita, thank you for your steady leadership and contribution. Undoubtedly, we will miss you next year when you retire. Over to you for financial metrics.

Ita Brennan{BIO 16651666 <GO>}
Thanks, Jayshree. That's very kind. It's been an amazing experience working with you and the whole Arista's team over the last eight years. Now back to the numbers. This analysis of our Q2 results and our guidance for Q3 is based on non-GAAP and excludes all non-cash stock-based compensation impacts, certain acquisition-related charges, and other non-recurring items. A full reconciliation of our selected GAAP to non-GAAP results is provided in our earnings release.

Total revenues in Q2 were $1.46 billion, up 38.7% year-over-year and well above the upper end of our guidance of $1.35 billion to $1.4 billion. Services and subscription software contributed approximately 15.2% of revenue in the quarter, up from 14.9% in Q1. International revenue to the quarter came in at $304.4 million or 20.9% of total revenue, up from 17.5% last quarter. This quarter-over-quarter increase largely reflected a healthy contribution from our enterprise customers in EMEA and APAC, and some reduction in domestic shipments to our cloud titan customers, which were unusually robust in the prior quarter. Overall gross margin in Q2 was 61.3%, in line with our guidance of approximately 61%, and up from 60.3% last quarter. We continue to see incremental improvements in gross margin quarter-over-quarter, with higher enterprise shipments and better supply chain costs, somewhat offset by the need for some additional inventory reserve as customers refine their forecasted product mix.

Operating expenses for the quarter were $287.3 million or 19.7% of revenue, up from last quarter at $257.5 million. R&D spending came in at $188.5 million or 12.9% of revenue, up from $164.8 million last quarter. This primarily reflected increased headcount and higher new product introduction costs in the period. Sales and marketing expense was $79.6 million or 5.5% of revenue, compared to $75.9 million last quarter with increased headcount and product demo costs. Our G&A costs committed $19.1 million or 1.3% of revenue, consistent with last quarter. Our operating income for the quarter was $606.5 million or 41.6% of revenue. Other income expense for the quarter was a favorable $31.6 million, and our effective tax rate was 21.4%. This resulted in net income for the quarter of $501.2 million or 34.4% of revenue. Our diluted share number was 316.5 million shares, resulting in a diluted earnings per share number for the quarter of $1.58, up 46% from the prior year.

Now, turning to the balance sheet. Cash, cash equivalents, and investments ended the quarter at approximately $3.7 billion. In the quarter, we repurchased $30 million of our common stock at an average price of $137.2 per share. We've now repurchased $855.5 million or 8 million shares at an average price of $107 per share under our current $1 billion forward authorization. This leaves $145 million available for repurchase in future quarters. The actual timing and amount of future repurchases will be dependent on market and business conditions, stock price, and other factors.

Now turning to operating cash performance in the second quarter. We generated approximately $434.1 million of cash from operations in the period, affecting strong earnings performance, partially offset by ongoing investments in working capital. DSOs came in at 49 days, down from 57 days in Q1, protecting a strong collections quarter with good linearity of billings. Inventory turns were 1.2x down from 1.3x last quarter. Inventory increased to $1.9 billion in the quarter, up from $1.7 billion in the prior period, reflecting the receipt of components from our purchase commitment and an increase in switch-related finished goods. Our purchase commitments at the end of the quarter were $2.2 billion, down from $2.9 billion at the end of Q1. We expect this number to continue to decline in future quarters as component lease times improve and we work to optimize our supply positions.

Our total deferred revenue balance was $1.085 billion, down from $1.092 billion in Q1. The majority of the deferred revenue balance is services-related and directly linked to the timing and term of service contracts, which can vary on a quarter-by-quarter basis. Our product deferred revenue balance declined approximately $33 million from last quarter. Accounts payable days are 57 days, up from 55 days in Q1, reflecting the timing of inventory receipts and payments. Capital expenditures in the quarter were $11.6 million.

Now turn to our outlook for the third quarter and beyond. To recap, global supply chain disruptions over the last couple of years necessitated elongated planning horizons and customer demand signals. The corollary results are true. Improving lead time are now driving shorter planning horizons and demand signals, delaying when customers need to place new orders. This is particularly true of our cloud titan customers who following a year of elevated purchases must now grapple with changing technology roadmaps and priorities before providing visibility to future demand later in the year. On the supply side, we expect to continue to ship against previously committed deployment plans for some time, targeting supply improvements where most needed but also careful not to create redundant customer inventory. In spite of the return to shorter lead times to reduce visibility, we are executing well with gradual incremental improvements for our 2023 outlook, which now calls for year-over-year growth in excess of 30%. On the gross margin front, we expect continued progress through the end of the year, reflecting supply chain and manufacturing benefits while maintaining a reasonably healthy cloud contribution.

Now turning to spending and investments. We continue to monitor the overall macro environment carefully. We'll prioritize our investments as we move through the year. This will include a focus on targeted hires in R&D and go to market as the team sees the opportunity to add talent. On the cash front, while we'll continue to focus on supply chain and working capital optimization, you should expect some continued growth in inventory through the end of the year. Also, as a reminder, our 2023 tax payments have been deferred to October and will represent a significant use of cash in that quarter. With all of this as a backdrop, our guidance for the third quarter based on non-GAAP result excludes any non-cash stock-based compensation impacts. Now the non-recurring items is as follows. Revenues of approximately $1.45 billion to $1.5 billion, gross margin of approximately 62%, operating margin at approximately 41%, our effective tax rate is expected to be approximately 21.5% with diluted shares of approximately 318 million shares.

I will now turn the call back to Liz. Liz?

Liz Stine{BIO 22543302 <GO>}
Thank you, Ita. We will now move to the Q&A portion of the Arista earnings call. To allow for greater participation, I'd like to request that everyone please limit themselves to a single question. Thank you for your understanding. Operator, take it away.

Questions And Answers
Operator
(Question And Answer)

Thank you. We will now begin the Q&A portion of the Arista earnings call. (Operator Instructions) Your first question comes from the line of William Ng with Goldman Sachs.

Q - Michael Ng{BIO 18285376 <GO>}
Hey, this is Mike Ng from Goldman Sachs. Thanks for the question. I was just wondering if you could talk a little bit more about the outlook for an excess of 30% year-over-year growth this year on revenue. What's gotten better relative to last earnings call? If you could talk about it in the context of cloud titans versus enterprise, that'd be helpful. I'm just trying to reconcile the revenue upgrade versus the commentary about your near-term cloud titan growth moderating. Thank you.

A - Jayshree V. Ullal{BIO 1737637 <GO>}
Yes. Thanks, Mike. I think it's pretty clear that from quarter-over-quarter our enterprise momentum continues to get stronger and better. And our cloud is strong, however, it's got two components now, there's the classic cloud networking and then the AI. So, we're reconciling how we double down more on AI, which we are feeling stronger and stronger about. And even on the cloud, you know that the last two years have just been out of this world and phenomenal. So, while it's moderating, it's still pretty good.

A - Liz Stine{BIO 22543302 <GO>}
Thanks, Mike. Next question.

Q - Michael Ng{BIO 18285376 <GO>}
Thanks, Jayshree.

Operator
We'll take our next question from Tim Long with Barclays.

Q - Tim Long{BIO 17361522 <GO>}
Thank you. Jayshree, I was hoping you could dig more into some of the comments around AI. Sounds like there's a large pipeline there, and you talked about kind of the stages with 2025 being the big growth area. I'm curious if you can just talk a little bit about a few things related to that. One, do you see that the move to AI expanding or diversifying more your cloud titan or your cloud customers? And second, can you talk about kind of the next year or two, the entire InfiniBand versus Ethernet debate? I think you guys have been trialing some Ethernet inside clusters, can you just give us an update on how you think that -- competition between those two technologies? How you think that's going to play out? Thank you.

A - Jayshree V. Ullal{BIO 1737637 <GO>}
Okay. Thank you, Tim. Maybe my answer will be shorter than your question. But I think the gist of what I'd like to first of all say is, majority of Arista's participation has been in the front end of the network, right? And we're getting a chance for the first time ever to play in the back end. So when we think AI, there's clearly some ramifications of bandwidth on the front end of the network but we're not counting that. So, we're truly thinking of something that's incremental, brand new, a lot of work to do in testing, proving, pilots, trials, before we get into production.

Today, I would say in the back end of the network, there are basically three classes of networks. One is very, very small networks that are within a server where customers use TCIE, CXL, there's proprietary NVIDIA specific technologies like NVLink that Arista does not participate. Then there's more medium clusters, you can think generative AI or inference, where they may well get built on Ethernet. For the extremely large clusters with large language training models, especially with the advent of ChatGPT 3 and 4, you're not talking about not just billion parameters but an aggregate of trillion parameters. And this is where Ethernet will shine.

But today, the only technology that is available to customers is InfiniBand. So obviously, InfiniBand with 10 years, 15 years of similarity in an HPC environment is often being bundled with the GPUs. But the right long-term technology is Ethernet, which is why I'm so proud of what the Ultra Ethernet Consortium and a number of vendors are doing to make that happen. So near-term, there's going to be a lot of InfiniBand and Arista will be watching that outside in, but longer term, Arista will be participating in an Ethernet AI network. And neither technology, I want to say, were perfectly designed for AI. InfiniBand was more focused on HPC, and Ethernet was more focused on general purpose networking. So, I think the work we are doing with the UAC to improve Ethernet for AI is very important.

Q - Tim Long{BIO 17361522 <GO>}
Okay. Thank you. That's very helpful.

Operator
We'll take our next question from Meta Marshall with Morgan Stanley.

Q - Meta Marshall{BIO 18728692 <GO>}
Great. Thanks. I mean, just revisiting kind of the cloud titan commentary. Does the change that you're seeing mean that they're completing kind of one upgrade cycle, there might just be time between the next upgrade cycle? Or are there real changes to kind of current deployment plans or kind of deployments of the current upgrades? Thanks.

A - Liz Stine{BIO 22543302 <GO>}
So, Meta you were addressing the question to Ita?

Q - Meta Marshall{BIO 18728692 <GO>}
I guess, I was addressing to whoever wants to answer about the kind of commentary on the changes in the cloud titan order.

A - Jayshree V. Ullal{BIO 1737637 <GO>}
Go for it, Anshul.

A - Anshul Sadana{BIO 16683800 <GO>}
Sure. When you look at the cloud customers in the last few quarters, especially since the advent of ChatGPT, there's been a rotation into AI. It's not that they're done with the upgrades or they're (inaudible) the upgrades, but they had to reprioritize their business and their deployment for AI. You've seen the competitive battle between the largest of the largest titans in the world trying to get ahead. But we see signs of that toying, and in the future, we believe they'll be back to adding and refreshing the standard computer infrastructure as well.

A - Jayshree V. Ullal{BIO 1737637 <GO>}
I always like to think that you can only do so for so long, eventually you have to eat. So I think we will see a nice mix of AI and classic cloud networking over time.

A - Ita Brennan{BIO 16651666 <GO>}
Yes. And I think that the lead time improvements have kind of facilitated them waiting for a little bit longer than what we've gotten used to over the last couple of years. But I think, again, that's kind of, we're going to start coming within lead time here pretty soon, then we'll see. Yes.

Q - Meta Marshall{BIO 18728692 <GO>}
Thank you.

A - Liz Stine{BIO 22543302 <GO>}
Thanks, Meta.

Operator
We'll take our next question from Ben Bollin with Cleveland Research.

Q - Ben Bollin{BIO 7475003 <GO>}
Hey. Good evening, everyone. Thanks for taking the question. Ita, congrats. I had a question for you. I was hoping you could speak to where you see lead times presently? And you talked about taking a little bit more managed approach to inventory levels at customers. Could you talk about some strategies that you employ to manage that and where you might see -- where you think inventory levels are within those accounts? Thank you.

A - Ita Brennan{BIO 16651666 <GO>}
Yes. I think, look, the lead times mixed across products. I mean, our goal certainly is to try to get back to like a six month lead time here. Maybe the end of the year, certainly early next year. But it is currently mixed across products. The commentary around customer inventory and stuff, we've been very diligent all the way through this process, the supply chain processes, trying to make sure we understood demand when it showed up and that it was being put into reasonable deployment schedules and deployment plans. And we just want to continue to do that as we come through the other side of really that whole supply chain disruption.

So it's really more understanding kind of -- what customers need? When they need it? And again, being able to prioritize and make sure that we understand that. So it's really a continuation of what we were doing, honestly, on the other side of the supply chain when you have these -- we have this kind of accelerated demand and then we were very focused on deployment schedules and timing. And this is just the other side of that, again, making sure we understand what's happening.

Q - Ben Bollin{BIO 7475003 <GO>}
Thank you.

Operator
We'll take our next question from Antoine Chkaiban with New Street Research.

Q - Antoine Chkaiban{BIO 21142044 <GO>}
Hi. Thanks a lot for taking my question. This is maybe a bit of a longer term question, but can you please provide an update on the opportunity at hyperscalers beyond your two largest customers? Does the accelerated deployment of AI clusters potentially open the door to business with the other two hyperscalers as the complexity of the networks is increasing rapidly?

A - Anshul Sadana{BIO 16683800 <GO>}
Sure. This gets asked very often, how we're doing that? And we continue to do well with them. As I mentioned before, not all titans are the same in terms of size. Some are small and we do very well with them, but they're just not as big as our two largest customers. And others who have the potential, we're still doing very well technologically with them, but we haven't seen the opportunity materialize. It's not that we're losing to anybody, it's just nothing has changed. And we continue to invest with them, and we believe the opportunity is still ahead of us.

A - Jayshree V. Ullal{BIO 1737637 <GO>}
Exactly, Anshul. I think the way to look at our AI opportunity is, it's 10 years ahead of us. And we'll have early customers in the cloud with very large data sets, trialing our Ethernet now. And then we will have more cloud customers, not only titans but other high-end tier two cloud providers and enterprises with large data sets that would also trial us over time. So, in 2025, expect to have a large list of customers of which cloud titans will still end up being some of the biggest but not the only ones.

A - Liz Stine{BIO 22543302 <GO>}
Thanks, Antoine.

Operator
Our next question comes from Amit Daryanani with Evercore.

Q - Amit Daryanani{BIO 7113568 <GO>}
Thanks and congrats on a nice quarter here. I guess my question is really, there's been a fair bit of debate among investors on what does calendar 24 look like for Arista, and the fear I think always is it could look like calendar 20 when you have some cloud digestion. I realize it's really early for you to guide '24, but if you just sort of think about the puts and takes into next year, that would be helpful. And maybe Jayshree, you could talk about how do you think Arista is different today versus in the calendar '19 and the '20 timeframe, that would be helpful.

A - Jayshree V. Ullal{BIO 1737637 <GO>}
Yes. No, that's a really good question. Stay tuned for our 2024 guide when we have our Annuals Day sometime in November. But qualitatively speaking, they're a very different company today than three years ago. Clearly we've doubled down on our cloud titans and you know that they're getting stronger and stronger. But even in the cloud titans, Arista and the team have worked to have a number of use cases, it isn't just one. And the addition of AI to that use cases just gave us a whole lot of broad opportunity from front end to back end, right?

So to me, the holistic and seamless and cohesion between the front end and back end will get even more important as time goes on in cloud titans. We also see that we're stronger in tier two providers and of course, the broader enterprise. Both of these were not as strong for us three years ago. And they also represent AI opportunities, but as you know, they represent campus, routing, classical data center opportunities and allow us to go -- target a much larger-term. Again, three years ago, it was probably 30 billion, three years later, it's well north of $50 billion. So, I feel we are much more diversified and while we deeply appreciate M&M, we got a lot more candy beyond that.

A - Liz Stine{BIO 22543302 <GO>}
Thank you, Amit.

Q - Amit Daryanani{BIO 7113568 <GO>}
Thank you.

Operator
We'll take our next question from Tal Liani with Bank of America.

Q - Tal Liani{BIO 1643846 <GO>}
Hi, Ita. I have to ask you a tough one before you go. So have a good taste for the rest few years. How much of the growth this time is coming from backlog drawdown? Can you give us some information about the order trends rather than revenues? And the reason why I'm asking it is because your guidance for 3Q is 25% growth. When I look at 4Q, it's -- the implied is 11%, so there is a sharp deceleration in growth in 4Q. And I'm wondering if it's a function of backlog and of elevated backlog. Thanks.

A - Ita Brennan{BIO 16651666 <GO>}
I mean, look, we haven't talked about backlog and orders. I think we've talked more just in terms of deployments and deployment slots. And if you think back to my commentary, I mean, we do believe that there are ongoing deployments that will go well into 2024, so it's not -- again, I don't necessarily sign up to the terminology of the backlog and the drawdown, et cetera, because it's just given how the orders and the patterns of the orders, it's very difficult to talk in that language, right?

But I think in terms of deployments, you will have deployments that are already planned and scheduled into 2024. I think, we're taking it quarter-by-quarter through the end of the year, but I'd still go back to my kind of incremental, look at it kind of incrementally quarter-over-quarter and continue to show some improvement. As we've guided Q3, so Q4 is -- take some similar kind of incremental improvement into Q4, and I think that's the way to think about it for now. But again, I don't know that it's -- our commentary on kind of demand and lead time stands, right? I mean, as lead times shorten, you will see some period of time where customers don't need to place orders until you get back into lead time, and that dynamic is certainly there. And as we get closer to the end of the year, we'll get more visibility into next year.

A - Jayshree V. Ullal{BIO 1737637 <GO>}
Tom, I think -- I know you asked a difficult question. Look, it's a -- we'll know more as time goes. And we think the business is strong, and whether it comes in strongly in '24 or '25 or somewhere in between, we shall see, right? And the reality is, it'll be difficult to repeat the last two years of exceptional cloud CapEx for cloud networking. So, as they go through that deployment, and as they look at AI, and as we bring in the enterprise and tier two cloud, we've got a nice mix of things. And I urge everyone to think about business as Ita has always alluded to, not in one quarter or even one year, but really a three-year CAGR. And I think, our three-year CAGR will continue to be in double digits and good numbers.

Q - Tal Liani{BIO 1643846 <GO>}
Great. Thank you.

A - Ita Brennan{BIO 16651666 <GO>}
Thanks, Tom.

Operator
We'll take our next question from Sebastian Naji with William Blair.

Q - Sebastian Naji
Great. Thanks for taking the question. Can you maybe just update us on the visibility in your customer base? Is it still around six months or are we now down closer to three months? And maybe just longer-term, do you think that generative AI could help improve that visibility from where it's historically been, just given that many of these hyperscalers have what seems like decent visibility into a pretty robust pipeline over the next few years?

A - Jayshree V. Ullal{BIO 1737637 <GO>}
Yes. That's a really good question, Sebastian. Since we have so many products in the mix, I have to break your question into visibility across multiple areas. Enterprise, I would say, 6 months to 12 months, generally speaking. In the cloud, given the reduced lead times on classic cloud networking, it's less than six months. However, on AI, it is greater since it's an early cycle and we have to do a lot more joint development. So, you can think of it as three migrations going on with different visibility patterns.

A - Liz Stine{BIO 22543302 <GO>}
Thanks, Sebastian.

Q - Sebastian Naji
Thank you.

Operator
We'll take our next question from Samik Chatterjee with JP Morgan.

Q - Samik Chatterjee{BIO 15496543 <GO>}
Hi, thanks for taking my question. Maybe if I can shift gears here a bit to enterprise, Jayshree. And obviously you're talking about the slowdown on the cloud side here a bit going into 2024, but when you look at enterprise, how do you think about sustaining a growth rate or the slowdown in that growth rate into 2024? What are you seeing in terms of autos on that front to sort of give you visibility into 2024? Thank you.

A - Jayshree V. Ullal{BIO 1737637 <GO>}
Look, I think Samik, this is an area that we feel pretty good about, and it's an area of great execution from Anshul, Chris Schmidt, Ashwin, and the entire team, where we have really diversified our business globally in the enterprise. We're not just in the high-end financials, we're in just about every major vertical, healthcare, transportation, public sector, education, banks, insurances. So I feel enterprise, barring any macro issue, which is the thing we were always worried about for 2024. So if macro doesn't let us down, and we don't have to worry about the economy, we will have a strong year in enterprise.

Q - Samik Chatterjee{BIO 15496543 <GO>}
Thank you.

Operator
We'll take our next question from Aaron Rakers with Wells Fargo.

Q - Aaron Rakers{BIO 6649630 <GO>}
Yes. Thank you for taking the question. I guess I wanted to ask just on the product cycle cadence. There's a lot of focus from one of your key component suppliers in the merchant silicon side around 51.2 terabit silicon and obviously supporting the 800 gig cycle. I'm curious, how do you think about the timing of that? When do we start to see the materializing deployments of 800 gig? And maybe that's tied to AI, maybe it's not, but just curious to when that cycle you believe really starts to kick in.

A - Anshul Sadana{BIO 16683800 <GO>}
Aaron, we had the same discussion when the world went to 400 gig, I'll be switching from 100 gig to 400 gig. The reality was the customers continue to buy both 100 gig and 400 gig for different use cases. 51 TN, 800 gig especially, are being pulled by AI clusters, the AI teams, the way access to get their hands on it, move the data as quickly as possible and reduce the job completion times. So you'll see early traction there. You'll see -- Jayshree mentioned, trials really in '24, going into volume in '25. And that should be the ramp we'll follow for 800-gig. But that does not mean everything they just bought last few years -- at 400-gig for DCI or the spines and so on for classic clusters, we're going to get an upgrade to 800-gig. I think that's going to be a longer cycle. So you will see 100 gig, 200 gig, 400 gig and 800 gig get deployed in parallel as we enter that cycle in '24, '25.

Q - Aaron Rakers{BIO 6649630 <GO>}
Thank you.

A - Anshul Sadana{BIO 16683800 <GO>}
Thanks.

A - Jayshree V. Ullal{BIO 1737637 <GO>}
Thanks, Aaron.

Operator
We'll take our next question from Matthew Niknam with Deutsche Bank.

Q - Matthew Niknam{BIO 21568441 <GO>}
Hey. Thanks for taking the question. I'm just wondering, on the supply chain, if you can talk about how that's evolved over the last quarter. And as it relates to gross margins, I think you're messaging incremental improvements in 3Q and 4Q. Is that purely a function of easing supply chain or is there also maybe greater relative contribution from enterprise relative to cloud titans envisioned in the second half of the year as well? Thanks.

A - Ita Brennan{BIO 16651666 <GO>}
I mean, we're definitely seeing improvement on the supply chain side. We're seeing improvements with freight, improvements with just some of the expedite cost of the things that we were dealing with, and we're kind of inventoried and now we're releasing them. So, I think we're coming out from underneath that. Yes, there is some small shift in mix as well but it's still a good, strong cloud mix this quarter, this year. So, it's not like we're back to a heavy enterprise mix with cloud playing a much smaller part. There's still a very healthy kind of cloud mix in this year. So, it's more where we're eking back out our -- the supply chain stuff that we've incurred in the past.

A - Jayshree V. Ullal{BIO 1737637 <GO>}
Yes. No, I want to give a shout out, Marc Burkhardt, our new Senior VP of Manufacturing; and John McCool, both in the actual scene, have done a fantastic job of optimizing the supply chain. So, those improvements are really playing a role in our quarter to quarter gross margins.

A - Liz Stine{BIO 22543302 <GO>}
Thank you.

Q - Matthew Niknam{BIO 21568441 <GO>}
Thank you.

Operator
We'll take our next question from James Fish with Piper Sandler.

Q - James E. Fish{BIO 18284975 <GO>}
Hey. Thanks for the question. I just wanted to follow up around some of the prior questions asked, as many might have been asked already. But I know you guys aren't talking about visibility and don't discuss backlog, but is it still fair to assume that we should think about you guys returning to a normal environment from a supply perspective in the early part of next year? And I believe, Ita, you talked about underneath, assuming that hyperscalers or your cloud titans grow double digits for this year. Is it still fair to think about that kind of level for 2023?

A - Ita Brennan{BIO 16651666 <GO>}
Yes, I think absolutely right. And I think that we kind of forget that cloud is still an important part of 2023, right? We're still executing on deployments and planning that we did some time back, right, all the way through this year. So cloud is still a significant piece of the business in 2023.

A - Jayshree V. Ullal{BIO 1737637 <GO>}
Yes. And James, just to confirm, we expect a more normal setting in 2024 in terms of design. You're right to assume that.

A - Liz Stine{BIO 22543302 <GO>}
Thanks, James.

Operator
We'll take our next question from Simon Leopold with Raymond James.

Q - Simon Leopold{BIO 4081594 <GO>}
Thanks for taking the question. I wanted to see if you could maybe do a little bit of unpacking in terms of what's driving your enterprise business in that I think the conventional wisdom is that enterprises are challenged by recessionary forces on the cycle, and then the secular challenge around public clouded option means slowing. So, what do you see happening? How much of this success is related to market share gains? How much to general cycles, products, et cetera? If we could unpack the enterprise traction. Thank you.

A - Jayshree V. Ullal{BIO 1737637 <GO>}
Sure, Simon. Well, of course, we have market share gains. That is the result of our enterprise traction, I would say. But if you ask me, why are we winning in the enterprise? I would say number one, from an alternative perspective, our customers haven't had one for a very long time. They haven't had a high quality, high support, (Technical Difficulty) friendly software experience, a common Leaf/Spine architecture across their data center, campus routing in a long, long time.

So I think the architectural shift in the enterprise to move to a modern cloud operating model is the number one reason that Arista has been chosen. They are seeking our architecture for that quality experience. In fact, Anshul and I were just talking about the call. We use the word cloudify a lot and it's (inaudible) greatly right now that our high-end enterprises are really looking for the cloud principles, but however, on their premise.

In terms of the shift between workloads on the cloud and workloads on the enterprises, it depends on the customer. You still see some of the mid-market customers want to move their e-commerce workloads on the cloud, but a lot of their mission-critical applications stay on the premise. So a hybrid strategy continues to dominate the enterprise decisions for the data center.

Secondly, our entry into the campus and routing, as well as zero trust security, observability, et cetera, is adding more layers to the cake. So our product depth and breadth is getting better and better. So the cloud operating model, the product depth, and now, actually, we've been at it now for what do you say, Anshul, three to five years, maybe? So -- especially in the United States. We've got more work to do internationally. I would say we've been engaging with these customers. I remember when Ita and I had a discussion, I want to say five years ago, where she was right and I was wrong. And she persuaded me to invest more in the enterprise.

So I think all these things have gone into really making us who we are in the enterprise. And clearly, we are a gold standard, and we have a seat at the table there.

Q - Simon Leopold{BIO 4081594 <GO>}
Thank you.

A - Jayshree V. Ullal{BIO 1737637 <GO>}
Thank you, Simon.

Operator
We'll take our next question from David Vogt with UBS.

Q - David Vogt{BIO 21761779 <GO>}
Great. Thanks, guys, for taking the question. And congratulations, Ita. I just want to go back to the point and maybe help bridge the '23 to '24 to '25 commentary that Jayshree mentioned, sort of strong double-digit growth. I think in the past, you've talked about 15% growth across cycles. And I'm just trying to think through, is there enough in trials and pilots in '24 to kind of get you to that kind of mid-teens growth over the next couple of years? And if not, does that mean that your enterprise business has to remain incredibly robust in '24, upwards of high-teens to low-20% growth next year?

I know you're not giving guidance, but trying to kind of walk the bridge to get from where we are today to '25, where you're going to start to see more widespread AI deployments from a revenue recognition perspective. Thanks.

A - Ita Brennan{BIO 16651666 <GO>}
And now, you want us to go to '25 as well. I don't think we're ready to do that. That's a really good conversation for the (Technical Difficulty). I think we, obviously, we're very focused internally, as Jayshree reiterated earlier on, the business is a lot more robust with many different drivers. As you go through that period, cloud will ebb and flow, but it's still a healthy business. It has been a healthy business through those cycles. So, I think we've got a lot of the building blocks, but how we're going to assemble them, maybe we'll save for the Analyst Day.

A - Jayshree V. Ullal{BIO 1737637 <GO>}
We'll share the Lego plan more. But David, rest assured that we are aiming for at least double digits next year. And so, we'll go from there.

Q - David Vogt{BIO 21761779 <GO>}
Great. Thanks, guys, and congrats again.

A - Ita Brennan{BIO 16651666 <GO>}
Thank you.

A - Jayshree V. Ullal{BIO 1737637 <GO>}
Thank you.

Operator
We'll take our next question from Erik Suppiger with JMP Securities.

Q - Erik Suppiger{BIO 1756547 <GO>}
Yeah, thanks for taking the question. Maybe this is for Anshul. Can you just walk us through kind of how the cloud titans work? We hear a lot about them buying volumes of GPUs right now. At what point do their purchasing of GPUs translate into their demand for switches? How does it work with the trials and so on and so forth?

A - Anshul Sadana{BIO 16683800 <GO>}
Sure. There is no uniform recipe, but in general, when they're buying GPUs (Technical Difficulty) to connect, these could be out in a few quarters, depending on their timing of deployments. Do they build the network first, (Technical Difficulty) these are very large things.

Then, it takes them a couple of months, sometimes a quarter or more to fine-tune the cluster and benchmark and test everything before it is actually released to production. So you can think of that as sort of the basis, a couple of months, a couple of quarters minimum before you can get there. Sometimes, it adds up to about a year before you really ramp into production.

A - Liz Stine{BIO 22543302 <GO>}
Great. Thanks, Erik.

Operator
We'll take our next question from George Notter with Jefferies.

Q - George Notter{BIO 1556662 <GO>}
Hi, guys, thanks a lot. I guess I wanted to ask about your comments about 2025 participation in AI. Can you walk us through sort of the milestones that you see between now and then in terms of increasing Arista's participation? Certainly, there's new product development, there's market acceptance, I presume.

And then, also, I assume that you participate today with inferencing applications and that's by and large done on Ethernet. I think what we're really talking about is training, correct? So any more color there would be great. Thanks.

A - Jayshree V. Ullal{BIO 1737637 <GO>}
Yes, George. So I think, you can look at 2023 as really a year of planning for AI. Because as I said, there's tons and tons of GPUs being purchased. And then the question is, how is it being connected? So depending on whether they're small, medium or large, there are different technologies, but I'm going to stay focused on the large, because that's the biggest problem.

You are right to say some of them may be Ethernet or even a non-networking technology, just an I/O or a bus for smaller networks. But generally speaking, we're focusing on things that are much larger than 200 or even 1,000 GPUs. So that's the first thing.

So a lot of planning is going into that. And the planning basically is how do they get the GPUs? What is their application, what is the size of the cluster, what is the time, what is the large language model data sets, et cetera, and what is their network foundation?

In some cases where they just need to go quick and fast, as I explained before, it would not be uncommon to just bundle their GPUs with an existing technology like InfiniBand. But where they're really rolling out into 2025, they're doing more trials and pilots with us to see what the performance is, to see what the drop is, to see how many they can connect, what's the latency, what's the better entropy, what's the efficiency, et cetera. That's where we are today.

Now, we expect next year, this will translate to some, what I call pilots, because majority of them will happen in '25, but in '24 you'll start seeing, what do you say, Anshul, maybe, 4,000 to 8,000 GPUs?

A - Anshul Sadana{BIO 16683800 <GO>}
That's right, in that range.

A - Jayshree V. Ullal{BIO 1737637 <GO>}
In that range, okay. 4,000 to 8,000 GPUs at about 400 gig type clusters, but we'll actually put some production workloads on it. So I call them smaller pilots. But the real test of why you buy these expensive GPUs is in 2025, when you want a gap not just 4,000 to 8000, but 30,000, 50,000, maybe even 100,000. This is why 2025 is so critical.

And testing and taking out all the kinks out of the GPUs and networks is important, because your network is so -- a good network is so pivotal to getting the most out of your GPUs. If you have idling cycles on those GPUs, you've wasted thousands, if not millions of dollars. And so, I think that these next two years are crucial to getting the most out of these expensive GPUs and that's where the network really comes.

Anshul?

A - Anshul Sadana{BIO 16683800 <GO>}
If I can add one more thing here, your (Technical Difficulty), what are the milestones to get to these 2025 large-scale GPU deployment, there is one key milestone that has nothing to do with GPUs or our switches, which is does the customer have enough power and the site ready to deploy that many megawatts or gigawatts of capacity? And as you know, getting a 1500 megawatt site takes a couple of years, which is why this is a slow ramp. This is not suddenly turn on the key and you have thousands of GPUs.

A - Jayshree V. Ullal{BIO 1737637 <GO>}
Yeah, a really good point. Simple things like power and space are still vital.

A - Liz Stine{BIO 22543302 <GO>}
Thanks, George.

Operator
We'll take our next question from Karl Ackerman with BNP Paribas.

Q - Karl Ackerman{BIO 19693285 <GO>}
Yes, thank you. Jayshree, there's been some investor concern that hyperscale customers may focus more on white box solutions for 800 gig than in the 400 gig cycle. We're aware that some of your customers continue to adopt a dual-sourcing strategy, but if you could just comment on the potential for an upgrade cycle, as well as reuse risk on the transition to 800 gig, it would be very helpful. Thank you.

A - Jayshree V. Ullal{BIO 1737637 <GO>}
Sure. As you're probably well aware, the white box question has remained with Arista as one of the most popular questions asked right in the time of our IPO, whether it's 10 gig, 40 gig, 100 gig, 400 gig, or now you ask it at 800 gig.

I think there will always be an element of white box, if somebody is just looking to build something and throw in some quick traffic. But for some of these most mission-critical networks, it's less about the box and more about the software stack and how much performance, availability, power you really get out of this. So the cost of putting in the box, if you save something, if you even save something, is far dwarfed by the total optics you need to make that box work.

So we continue to believe that we will coexist with white box in some of our cloud titan customers. We will continue to run both SONiC and FBOSS in the case of Microsoft and Meta along with our EOS. But at the end of the day, whether it's a white box or a blue box, it's the software stack that really wins.

A - Liz Stine{BIO 22543302 <GO>}
Thanks, Carl. Operator, we have time for one last question.

Operator
Thank you. We'll take our last question from Ben Reitzes with Melius Research.

Q - Ben Reitzes{BIO 1880391 <GO>}
Hey, thanks a lot for sneaking me in there. Congratulations, Jayshree and team. I wanted to ask about enterprise again. I think the comments you made around cloud titans were all things that people were able to detect, but the enterprise just seems so much better in terms of the performance and the guide. So you mentioned that you gained share, but did the market pick up as well? And did you -- do you see that market pick up in demand and the enterprise sustaining into '24? Just kind of more color around enterprise and whether the market picked up in addition to you gaining share.

A - Jayshree V. Ullal{BIO 1737637 <GO>}
Hey, Ben, thank you. What do you mean by the seen by the market pickup? I don't follow the question.

Q - Ben Reitzes{BIO 1880391 <GO>}
Did demand pick up? Because the enterprise outperformance was quite a surprise. And clearly, the cloud titan commentary was subdued, as everybody was able to predict after the last conference calls this week. So I mean, was it all market share or is the market picking up? Is demand picking up across the board?

A - Jayshree V. Ullal{BIO 1737637 <GO>}
I would say to you that probably, our enterprise demand has always been strong and not subdued, far from that. However, dwarfed by the excellence of our cloud performance, you didn't notice it. And now, you're noticing it.

A - Liz Stine{BIO 22543302 <GO>}
Thanks, Ben. This concludes the Arista Networks second quarter 2023 earnings call. We have posted a presentation which provides additional information on our results, which you can access on our Investors section of our website. Thank you for joining us today and thank you for your interest in Arista.

Operator
Thank you for joining, ladies and gentlemen. This concludes today's call. You may now disconnect.